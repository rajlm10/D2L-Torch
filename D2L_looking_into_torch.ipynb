{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "D2L_looking_into_torch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN8aou8dwjW+bgAtBwstb8x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajlm10/D2L-Torch/blob/main/D2L_looking_into_torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TOdI9ZC1M3Aw"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "from torch import nn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Looking into the network"
      ],
      "metadata": {
        "id": "QwPXuvkRNL5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net=nn.Sequential(nn.Linear(4,8),nn.ReLU(),nn.Linear(8,1))\n",
        "X=torch.randn((2,4))\n",
        "net(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BjducwZNJRQ",
        "outputId": "e32c5fb7-1e29-4b7a-c665-0310b6921cda"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2962],\n",
              "        [0.3001]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pTUiQphNrlA",
        "outputId": "990a49c8-983f-4aef-d12d-307328e40f94"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('0.weight', tensor([[ 0.2325, -0.3744, -0.3166, -0.0389],\n",
              "                      [ 0.1322, -0.4116,  0.0858, -0.1902],\n",
              "                      [ 0.3968,  0.3834, -0.4747, -0.4488],\n",
              "                      [ 0.4977,  0.0027,  0.2182,  0.1547],\n",
              "                      [-0.2413, -0.3645, -0.4239, -0.0569],\n",
              "                      [ 0.1880,  0.1750, -0.4226,  0.3092],\n",
              "                      [-0.2907,  0.0057, -0.3280, -0.4070],\n",
              "                      [-0.0546, -0.0281,  0.0794,  0.0119]])),\n",
              "             ('0.bias',\n",
              "              tensor([-0.3580, -0.4514, -0.2275,  0.1554,  0.0391, -0.4588, -0.1121, -0.2823])),\n",
              "             ('2.weight',\n",
              "              tensor([[-0.2201, -0.1809,  0.0803, -0.0132, -0.1396,  0.0477,  0.2607,  0.2682]])),\n",
              "             ('2.bias', tensor([0.2864]))])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net.state_dict()['0.weight'],net.state_dict()['0.weight'].grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCFbKI_hNwbB",
        "outputId": "997e05f5-d606-4926-e1cf-e16b813f7ca8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.2325, -0.3744, -0.3166, -0.0389],\n",
              "         [ 0.1322, -0.4116,  0.0858, -0.1902],\n",
              "         [ 0.3968,  0.3834, -0.4747, -0.4488],\n",
              "         [ 0.4977,  0.0027,  0.2182,  0.1547],\n",
              "         [-0.2413, -0.3645, -0.4239, -0.0569],\n",
              "         [ 0.1880,  0.1750, -0.4226,  0.3092],\n",
              "         [-0.2907,  0.0057, -0.3280, -0.4070],\n",
              "         [-0.0546, -0.0281,  0.0794,  0.0119]]), None)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net[2].state_dict()['weight'].requires_grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjLNVKe9OMUg",
        "outputId": "2b43fd57-3815-4c61-bf5d-3433ce52dda6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def block1():\n",
        "  return nn.Sequential(nn.Linear(4, 8), nn.ReLU(),nn.Linear(8, 4), nn.ReLU())\n",
        "\n",
        "def block2():\n",
        "  net = nn.Sequential() \n",
        "  for i in range(4):\n",
        "  # Nested here\n",
        "    net.add_module(f'block {i}', block1()) \n",
        "  return net\n",
        "rgnet = nn.Sequential(block2(), nn.Linear(4, 1)) \n",
        "rgnet(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyKSK9b1Op2Q",
        "outputId": "e913bbb9-7334-471a-b902-ea257c5c91ce"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1099],\n",
              "        [0.1099]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rgnet.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7Qo-qroO01P",
        "outputId": "5d17789e-fb5c-4d30-e10f-387d4c286cae"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('0.block 0.0.weight',\n",
              "              tensor([[ 0.3095, -0.4278,  0.2792,  0.2865],\n",
              "                      [ 0.1315, -0.4395, -0.3540,  0.1121],\n",
              "                      [ 0.3170, -0.1404, -0.4724,  0.0797],\n",
              "                      [ 0.4650,  0.3947,  0.2618,  0.4645],\n",
              "                      [-0.3625, -0.2194,  0.1755, -0.0928],\n",
              "                      [-0.1427, -0.1425, -0.1731, -0.0334],\n",
              "                      [-0.4787,  0.2730,  0.3682, -0.1145],\n",
              "                      [ 0.0798, -0.4522,  0.3958,  0.4812]])),\n",
              "             ('0.block 0.0.bias',\n",
              "              tensor([-0.3687, -0.4589,  0.4744,  0.2302,  0.2669, -0.3121,  0.1756, -0.1354])),\n",
              "             ('0.block 0.2.weight',\n",
              "              tensor([[-0.0834, -0.2594, -0.0756, -0.0117,  0.2090, -0.3183, -0.3004, -0.0967],\n",
              "                      [-0.3131, -0.3262,  0.0870, -0.2777,  0.1776,  0.2034, -0.0738, -0.2732],\n",
              "                      [ 0.1142, -0.1988, -0.3177,  0.1647,  0.2563,  0.2981,  0.0535,  0.2462],\n",
              "                      [ 0.2341, -0.2195,  0.1245, -0.2714, -0.2339, -0.2550,  0.0587, -0.0932]])),\n",
              "             ('0.block 0.2.bias',\n",
              "              tensor([-0.2008, -0.1095,  0.1060, -0.3419])),\n",
              "             ('0.block 1.0.weight',\n",
              "              tensor([[-0.2336, -0.3799,  0.0429,  0.2893],\n",
              "                      [ 0.0210, -0.3343, -0.3611, -0.4517],\n",
              "                      [-0.0283, -0.4304,  0.3277, -0.0358],\n",
              "                      [-0.1214, -0.1149, -0.3328, -0.1865],\n",
              "                      [-0.4700, -0.4097, -0.1315, -0.0612],\n",
              "                      [ 0.0234,  0.0319, -0.3215,  0.1230],\n",
              "                      [-0.4928,  0.1294,  0.3956,  0.0258],\n",
              "                      [-0.3705,  0.3608, -0.1756,  0.3605]])),\n",
              "             ('0.block 1.0.bias',\n",
              "              tensor([-0.2015,  0.0501,  0.2634,  0.0837,  0.0198,  0.4460,  0.1619, -0.2026])),\n",
              "             ('0.block 1.2.weight',\n",
              "              tensor([[-0.3088, -0.0686,  0.3389, -0.0499,  0.0944,  0.0364,  0.0269, -0.1468],\n",
              "                      [-0.1079,  0.0374, -0.3202, -0.3482, -0.2233,  0.0641,  0.1868,  0.3367],\n",
              "                      [ 0.1937, -0.1875,  0.0258,  0.2158, -0.0949, -0.3533,  0.2577, -0.1057],\n",
              "                      [ 0.1870, -0.0444,  0.0217,  0.2443,  0.2390, -0.0766, -0.0419, -0.3509]])),\n",
              "             ('0.block 1.2.bias',\n",
              "              tensor([-0.3482,  0.0127, -0.0414,  0.2088])),\n",
              "             ('0.block 2.0.weight',\n",
              "              tensor([[ 0.4313, -0.4258,  0.4720,  0.1827],\n",
              "                      [-0.0177, -0.1527,  0.2658,  0.2027],\n",
              "                      [-0.2973, -0.0831, -0.0964, -0.0570],\n",
              "                      [ 0.2331, -0.1092,  0.4585,  0.4148],\n",
              "                      [ 0.0094,  0.0493, -0.2737, -0.0403],\n",
              "                      [ 0.3581, -0.3003, -0.1709,  0.3772],\n",
              "                      [ 0.2625,  0.1400, -0.1389,  0.4533],\n",
              "                      [-0.4386, -0.2204, -0.1693,  0.1728]])),\n",
              "             ('0.block 2.0.bias',\n",
              "              tensor([-0.3431,  0.0158,  0.0442, -0.4735,  0.2463,  0.2191, -0.1962, -0.4569])),\n",
              "             ('0.block 2.2.weight',\n",
              "              tensor([[ 0.0526,  0.1991,  0.2052,  0.1481,  0.1479, -0.2547, -0.0807,  0.1342],\n",
              "                      [ 0.3480, -0.1467, -0.2470,  0.0672,  0.0499,  0.2056,  0.1146, -0.2828],\n",
              "                      [ 0.0956,  0.3155,  0.0295,  0.0647, -0.3013,  0.2094, -0.0452,  0.0049],\n",
              "                      [-0.2750,  0.2093, -0.2291, -0.0257,  0.1152,  0.3517, -0.3153, -0.0672]])),\n",
              "             ('0.block 2.2.bias',\n",
              "              tensor([ 0.2188,  0.0187, -0.1981,  0.2433])),\n",
              "             ('0.block 3.0.weight',\n",
              "              tensor([[-0.1917, -0.1586, -0.3059,  0.0252],\n",
              "                      [ 0.0993,  0.0948,  0.2462, -0.4268],\n",
              "                      [ 0.3981,  0.3028,  0.2626, -0.0511],\n",
              "                      [-0.0880,  0.3959, -0.1583, -0.3857],\n",
              "                      [-0.0800,  0.2760, -0.0643, -0.2576],\n",
              "                      [ 0.1935,  0.1346, -0.3634, -0.3231],\n",
              "                      [ 0.1852, -0.1495, -0.0901,  0.0260],\n",
              "                      [-0.1404,  0.0262, -0.0973, -0.2449]])),\n",
              "             ('0.block 3.0.bias',\n",
              "              tensor([-0.4458, -0.4355, -0.2402,  0.4505, -0.4988, -0.0926,  0.3343,  0.0445])),\n",
              "             ('0.block 3.2.weight',\n",
              "              tensor([[-0.0005,  0.2534,  0.2032, -0.0014, -0.0491,  0.0028, -0.0618, -0.1484],\n",
              "                      [-0.2561,  0.1951,  0.1176, -0.0708,  0.1297,  0.1329, -0.2570,  0.3027],\n",
              "                      [-0.0403,  0.2599, -0.1039, -0.1858,  0.2999, -0.2859,  0.0199, -0.2990],\n",
              "                      [-0.1203,  0.1876, -0.2944,  0.1091, -0.3290, -0.3480, -0.0950,  0.0827]])),\n",
              "             ('0.block 3.2.bias',\n",
              "              tensor([-0.3003, -0.2120,  0.0522,  0.3080])),\n",
              "             ('1.weight', tensor([[-0.4195, -0.2022, -0.2952, -0.2084]])),\n",
              "             ('1.bias', tensor([0.1741]))])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rgnet.state_dict()['0.block 0.2.weight']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTB8_MiNPVug",
        "outputId": "1f3b8681-586a-421f-ad3a-47cc617a6e19"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0834, -0.2594, -0.0756, -0.0117,  0.2090, -0.3183, -0.3004, -0.0967],\n",
              "        [-0.3131, -0.3262,  0.0870, -0.2777,  0.1776,  0.2034, -0.0738, -0.2732],\n",
              "        [ 0.1142, -0.1988, -0.3177,  0.1647,  0.2563,  0.2981,  0.0535,  0.2462],\n",
              "        [ 0.2341, -0.2195,  0.1245, -0.2714, -0.2339, -0.2550,  0.0587, -0.0932]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rgnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziCoAOSWPB03",
        "outputId": "a20837e6-b8e2-4724-9830-7977c850a5d9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Sequential(\n",
              "    (block 0): Sequential(\n",
              "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
              "      (3): ReLU()\n",
              "    )\n",
              "    (block 1): Sequential(\n",
              "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
              "      (3): ReLU()\n",
              "    )\n",
              "    (block 2): Sequential(\n",
              "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
              "      (3): ReLU()\n",
              "    )\n",
              "    (block 3): Sequential(\n",
              "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
              "      (3): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (1): Linear(in_features=4, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rgnet[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F23ym9q5PESj",
        "outputId": "79c515da-b8f3-4157-913b-756c24745ff5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (block 0): Sequential(\n",
              "    (0): Linear(in_features=4, out_features=8, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=8, out_features=4, bias=True)\n",
              "    (3): ReLU()\n",
              "  )\n",
              "  (block 1): Sequential(\n",
              "    (0): Linear(in_features=4, out_features=8, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=8, out_features=4, bias=True)\n",
              "    (3): ReLU()\n",
              "  )\n",
              "  (block 2): Sequential(\n",
              "    (0): Linear(in_features=4, out_features=8, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=8, out_features=4, bias=True)\n",
              "    (3): ReLU()\n",
              "  )\n",
              "  (block 3): Sequential(\n",
              "    (0): Linear(in_features=4, out_features=8, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=8, out_features=4, bias=True)\n",
              "    (3): ReLU()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rgnet[0][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "260G_CGmPKYS",
        "outputId": "8d541d7f-08ac-4ce1-9b8b-ff4abe3ba3c1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=4, out_features=8, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=8, out_features=4, bias=True)\n",
              "  (3): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rgnet[0][1][2].weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5-ap7maPNDk",
        "outputId": "d32422ba-389b-4ec5-926d-9861622f09bd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.3088, -0.0686,  0.3389, -0.0499,  0.0944,  0.0364,  0.0269, -0.1468],\n",
              "        [-0.1079,  0.0374, -0.3202, -0.3482, -0.2233,  0.0641,  0.1868,  0.3367],\n",
              "        [ 0.1937, -0.1875,  0.0258,  0.2158, -0.0949, -0.3533,  0.2577, -0.1057],\n",
              "        [ 0.1870, -0.0444,  0.0217,  0.2443,  0.2390, -0.0766, -0.0419, -0.3509]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialization for Linear Layers "
      ],
      "metadata": {
        "id": "N6GiM0OsPnxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_normal(layer):\n",
        "  if isinstance(layer,torch.nn.Linear):\n",
        "    nn.init.normal_(layer.weight,mean=0,std=0.01)\n",
        "    nn.init.zeros_(layer.bias)\n",
        "\n",
        "net.apply(init_normal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LD5wcq1uPrCa",
        "outputId": "6f1bbe8d-566f-451e-931d-88fcb9ec1688"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=4, out_features=8, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=8, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def init_xavier(layer):\n",
        "  if isinstance(layer,torch.nn.Linear):\n",
        "    nn.init.xavier_uniform_(layer.weight)\n",
        "    nn.init.zeros_(layer.bias)\n",
        "\n",
        "net.apply(init_xavier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUIME28SQJKp",
        "outputId": "314c4660-bf60-4663-cf7b-d7e93056ffe0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=4, out_features=8, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=8, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Shared Parameters "
      ],
      "metadata": {
        "id": "wmbBK80hQs9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to give the shared layer a name so that we can refer to its # parameters\n",
        "shared = nn.Linear(8, 8)\n",
        "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(),shared, nn.ReLU(), shared, nn.ReLU(), nn.Linear(8, 1))\n",
        "net(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_BE8c9tQvaT",
        "outputId": "cd98fc5a-0e60-486c-f604-f7737ded0e72"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0975],\n",
              "        [-0.0633]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check whether the parameters are the same\n",
        "print(net[2].weight.data[0] == net[4].weight.data[0])\n",
        "temp=net[2].weight.data[0, 0]\n",
        "net[2].weight.data[0, 0] = 100\n",
        "# Make sure that they are actually the same object rather than just having the # same value\n",
        "print(net[2].weight.data[0] == net[4].weight.data[0])\n",
        "net[2].weight.data[0, 0] = temp #restore after checking\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZOck_DaQ158",
        "outputId": "b86ec75a-9062-4912-8914-c730cbba2883"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([True, True, True, True, True, True, True, True])\n",
            "tensor([True, True, True, True, True, True, True, True])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving and loading tensors "
      ],
      "metadata": {
        "id": "cH7ajOljRG0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(4) \n",
        "torch.save(x, 'x-file')\n",
        "x2 = torch.load('x-file') \n",
        "x2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Nb7WYmBRJfB",
        "outputId": "98c5c5fc-10a3-4323-adec-2ccb50df8963"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mydict = {'x': x, 'y': x.clone()} \n",
        "torch.save(mydict, 'mydict') \n",
        "mydict2 = torch.load('mydict') \n",
        "mydict2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tVMoF4fRV2x",
        "outputId": "22c309e1-c5c6-45cc-f06c-05af8ca07b17"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'x': tensor([0, 1, 2, 3]), 'y': tensor([0, 1, 2, 3])}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module): \n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.hidden = nn.Linear(20, 256) \n",
        "    self.output = nn.Linear(256, 10)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.output(nn.ReLU()(self.hidden(x)))\n",
        "\n",
        "net = MLP()\n",
        "X = torch.randn(size=(2, 20)) \n",
        "Y = net(X)\n",
        "\n",
        "torch.save(net.state_dict(), 'mlp.params')"
      ],
      "metadata": {
        "id": "KdyXhk0BRktA"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clone = MLP()  #We need to recreate the architecture since we only save weights\n",
        "clone.load_state_dict(torch.load('mlp.params')) \n",
        "clone.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqKKNK5_RyqQ",
        "outputId": "2317923f-75a8-4193-bc28-ca28d24aba2e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
              "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_clone = clone(X) \n",
        "Y_clone == Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doXsJSDqSKnW",
        "outputId": "faf1dbd1-5057-47c7-f394-2fbcfbaf225e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True, True, True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPUs 101"
      ],
      "metadata": {
        "id": "Wky7JziqSOgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3UXdv65SQGw",
        "outputId": "3676210c-6ae7-497f-a409-e7e40a3afe94"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Mar 10 05:24:34 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   69C    P8    35W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.device_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8taQ47NSTGu",
        "outputId": "be726e6e-e6d9-449a-e667-da8244fa7285"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def try_gpu(i=0):\n",
        "  \"\"\"Return gpu(i) if exists, otherwise return cpu().\"\"\" \n",
        "  if torch.cuda.device_count() >= i + 1:\n",
        "    return torch.device(f'cuda:{i}') \n",
        "  return torch.device('cpu')\n",
        "\n",
        "def try_all_gpus():\n",
        "  \"\"\"Return all available GPUs, or [cpu(),] if no GPU exists.\"\"\" \n",
        "  devices = [torch.device(f'cuda:{i}') for i in range(torch.cuda.device_count())] \n",
        "  return devices if devices else [torch.device('cpu')]\n",
        "  \n",
        "try_gpu(), try_gpu(10), try_all_gpus()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeBtIa2qSZH4",
        "outputId": "b0724cee-b3c8-426d-e21d-201d16f0088f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(device(type='cuda', index=0),\n",
              " device(type='cpu'),\n",
              " [device(type='cuda', index=0)])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "z = torch.tensor([1, 2, 3]) #Default creation on CPU\n",
        "print(z.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysnl9FchStQc",
        "outputId": "0cb06bd1-2584-4a9d-ba17-90e22f9b1d73"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "CPU times: user 232 µs, sys: 48 µs, total: 280 µs\n",
            "Wall time: 206 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "y = torch.tensor([1, 2],device=try_gpu())\n",
        "print(y.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfnfZp_WSzJ0",
        "outputId": "4ed6e8ea-948d-47e5-9c6f-ab8d6fc1cc08"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "CPU times: user 361 µs, sys: 75 µs, total: 436 µs\n",
            "Wall time: 443 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = nn.Sequential(nn.Linear(3, 1)) \n",
        "net = net.to(device=try_gpu())\n",
        "\n",
        "net[0].weight.data.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXqvu03BTAOc",
        "outputId": "03aeaec0-5c29-4b43-efe5-0fbe835e7d34"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=torch.rand((3,3))\n",
        "\n",
        "net(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "e1eO24JgT1yj",
        "outputId": "176968f8-1f51-45de-87ac-43466c7b1209"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-34f8df2dc9a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)"
          ]
        }
      ]
    }
  ]
}