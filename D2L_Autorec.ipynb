{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "D2L_Autorec.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNyhRST/can+YDm+P4a6se2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajlm10/D2L-Torch/blob/main/D2L_Autorec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnr9pQehfC0J",
        "outputId": "9111922f-a31c-4608-cd02-b99b76297457"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 82 kB 705 kB/s \n",
            "\u001b[K     |████████████████████████████████| 61 kB 8.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 56.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 9.9 MB 53.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 11.2 MB 44.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 930 kB 43.1 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.25.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q d2l torchinfo\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import multiprocessing\n",
        "from torch import nn\n",
        "from d2l import torch as d2l\n",
        "from tqdm import tqdm\n",
        "import math\n"
      ],
      "metadata": {
        "id": "yUuAlMEPfwo4"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d2l.DATA_HUB['ml-100k'] = (\n",
        "    'https://files.grouplens.org/datasets/movielens/ml-100k.zip',\n",
        "    'cd4dcac4241c8a4ad7badc7ca635da8a69dddb83')\n",
        "\n",
        "def read_data_ml100k():\n",
        "    data_dir = d2l.download_extract('ml-100k')\n",
        "    names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
        "    data = pd.read_csv(os.path.join(data_dir, 'u.data'), '\\t', names=names,engine='python')\n",
        "    num_users = data.user_id.unique().shape[0]\n",
        "    num_items = data.item_id.unique().shape[0]\n",
        "    return data, num_users, num_items"
      ],
      "metadata": {
        "id": "UCkWmyi0fypA"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data, num_users, num_items = read_data_ml100k()\n",
        "sparsity = 1 - len(data) / (num_users * num_items)\n",
        "print(f'number of users: {num_users}, number of items: {num_items}')\n",
        "print(f'matrix sparsity: {sparsity:f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wo-SCsTZf0Ro",
        "outputId": "39ae4f7d-ae3b-4a9d-efe2-c0ff1eed8b86"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of users: 943, number of items: 1682\n",
            "matrix sparsity: 0.936953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OnkwvYC3f4LW",
        "outputId": "ec8d528c-eea1-4fb5-c747-445feb90f11f"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   user_id  item_id  rating  timestamp\n",
              "0      196      242       3  881250949\n",
              "1      186      302       3  891717742\n",
              "2       22      377       1  878887116\n",
              "3      244       51       2  880606923\n",
              "4      166      346       1  886397596"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eac01b16-f657-4b44-9021-6e96a44cc042\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eac01b16-f657-4b44-9021-6e96a44cc042')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eac01b16-f657-4b44-9021-6e96a44cc042 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eac01b16-f657-4b44-9021-6e96a44cc042');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAkF2-Qgf6Gs",
        "outputId": "9efaea71-8c9f-4aa1-c719-50aabb4ab19d"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 4 columns):\n",
            " #   Column     Non-Null Count   Dtype\n",
            "---  ------     --------------   -----\n",
            " 0   user_id    100000 non-null  int64\n",
            " 1   item_id    100000 non-null  int64\n",
            " 2   rating     100000 non-null  int64\n",
            " 3   timestamp  100000 non-null  int64\n",
            "dtypes: int64(4)\n",
            "memory usage: 3.1 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "fbASPODqf7xy",
        "outputId": "f3f9f10a-7a30-489f-d1b5-196354a5836f"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            user_id        item_id         rating     timestamp\n",
              "count  100000.00000  100000.000000  100000.000000  1.000000e+05\n",
              "mean      462.48475     425.530130       3.529860  8.835289e+08\n",
              "std       266.61442     330.798356       1.125674  5.343856e+06\n",
              "min         1.00000       1.000000       1.000000  8.747247e+08\n",
              "25%       254.00000     175.000000       3.000000  8.794487e+08\n",
              "50%       447.00000     322.000000       4.000000  8.828269e+08\n",
              "75%       682.00000     631.000000       4.000000  8.882600e+08\n",
              "max       943.00000    1682.000000       5.000000  8.932866e+08"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-18a6643a-6b75-4018-9167-2351cf858d7a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>100000.00000</td>\n",
              "      <td>100000.000000</td>\n",
              "      <td>100000.000000</td>\n",
              "      <td>1.000000e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>462.48475</td>\n",
              "      <td>425.530130</td>\n",
              "      <td>3.529860</td>\n",
              "      <td>8.835289e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>266.61442</td>\n",
              "      <td>330.798356</td>\n",
              "      <td>1.125674</td>\n",
              "      <td>5.343856e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.747247e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>254.00000</td>\n",
              "      <td>175.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>8.794487e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>447.00000</td>\n",
              "      <td>322.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>8.828269e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>682.00000</td>\n",
              "      <td>631.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>8.882600e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>943.00000</td>\n",
              "      <td>1682.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>8.932866e+08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18a6643a-6b75-4018-9167-2351cf858d7a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-18a6643a-6b75-4018-9167-2351cf858d7a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-18a6643a-6b75-4018-9167-2351cf858d7a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d2l.plt.hist(data['rating'], bins=5, ec='black')\n",
        "d2l.plt.xlabel('Rating')\n",
        "d2l.plt.ylabel('Count')\n",
        "d2l.plt.title('Distribution of Ratings in MovieLens 100K')\n",
        "d2l.plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "PAFAEvYnf9yD",
        "outputId": "e55e0454-68fe-4c88-8666-1981888c04b9"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Splitting the data\n",
        "\n",
        "We split the dataset into training and test sets. The following function provides two split modes including random and seq-aware. In the random mode, the function splits the 100k interactions randomly without considering timestamp and uses the 90% of the data as training samples and the rest 10% as test samples by default. In the seq-aware mode, we leave out the item that a user rated most recently for test, and users’ historical interactions as training set. User historical interactions are sorted from oldest to newest based on timestamp. This mode will be used in the sequence-aware recommendation section."
      ],
      "metadata": {
        "id": "D9DB64-mgDRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We have atleast 96 entries per user\n",
        "#If we had 1 entry only, we can't use it in the test set and hence can omit that user\n",
        "min(data.groupby('user_id')['user_id'].sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzIVezRGgAjy",
        "outputId": "67c0b28d-84bf-4b74-fdd4-ee1d1b47b971"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data_ml100k(data, num_users, num_items,\n",
        "                      split_mode='random', test_ratio=0.1):\n",
        "    \"\"\"Split the dataset in random mode or seq-aware mode.\"\"\"\n",
        "    columns= list(data.columns)\n",
        "    if split_mode == 'seq-aware':\n",
        "        train_items, test_items, train_list = {}, {}, []\n",
        "        for line in tqdm(data.to_dict('records')):\n",
        "            u, i, rating, time = line['user_id'], line['item_id'], line['rating'], line['timestamp']\n",
        "            #key-> user_id value-> all instances of u\n",
        "            train_items.setdefault(u, []).append((u, i, rating, time))\n",
        "            #for every unique u make an entry and if u already exists\n",
        "            # replace the entry by most recent entry for u\n",
        "            if u not in test_items or test_items[u][-1] < time:\n",
        "                test_items[u] = (i, rating, time)\n",
        "        for u in range(1, num_users + 1):\n",
        "            #list of tuples\n",
        "            train_list.extend(sorted(train_items[u], key=lambda k: k[-1]))\n",
        "        test_data = [(key, *value) for key, value in test_items.items()]\n",
        "        train_data = [item for item in train_list if item not in test_data]\n",
        "        train_data = pd.DataFrame(train_data,columns=columns)\n",
        "        test_data = pd.DataFrame(test_data,columns=columns)\n",
        "    else:\n",
        "        mask = [True if x == 1 else False for x in np.random.uniform(\n",
        "            0, 1, (len(data))) < 1 - test_ratio]\n",
        "        neg_mask = [not x for x in mask]\n",
        "        train_data, test_data = data[mask], data[neg_mask]\n",
        "    return train_data, test_data"
      ],
      "metadata": {
        "id": "FvZ0J3SLgIi_"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Data\n",
        "After dataset splitting, we will convert the training set and test set into lists and dictionaries/matrix for the sake of convenience. The following function reads the dataframe line by line and enumerates the index of users/items start from zero. The function then returns lists of users, items, ratings and a dictionary/matrix that records the interactions. We can specify the type of feedback to either explicit or implicit"
      ],
      "metadata": {
        "id": "UeXKBpyIgNDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_ml100k(data, num_users, num_items, feedback='explicit'):\n",
        "    users, items, scores = [], [], []\n",
        "    inter = np.zeros((num_items, num_users)) if feedback == 'explicit' else {}\n",
        "    for line in tqdm(data.to_dict('records')):\n",
        "        #subtract 1 since user_id & item_id start from 1\n",
        "        user_index, item_index = int(line['user_id'] - 1), int(line['item_id'] - 1)\n",
        "        score = int(line['rating']) if feedback == 'explicit' else 1\n",
        "        users.append(user_index) #len num interactions\n",
        "        items.append(item_index) #len num interactions\n",
        "        scores.append(score)     #len num interactions\n",
        "        if feedback == 'implicit':\n",
        "            #for each user, list of items interacted with\n",
        "            inter.setdefault(user_index, []).append(item_index)\n",
        "        else:\n",
        "            #num_items x num_users matrix with interaction scores at each position\n",
        "            inter[item_index, user_index] = score\n",
        "    return users, items, scores, inter"
      ],
      "metadata": {
        "id": "G78DGUbKgK9g"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_iterator(dataset,batch_size,is_train=True):\n",
        "  return torch.utils.data.DataLoader(dataset,batch_size,shuffle=is_train,num_workers=multiprocessing.cpu_count())"
      ],
      "metadata": {
        "id": "bZf0VWuLgVKS"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(*torch.tensor(np.array([[1,2],[2,1]])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evC_SATCoQd9",
        "outputId": "6c04be91-796d-46e6-b6e6-2f53a51047c6"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2]) tensor([2, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_and_load_ml100k(split_mode='seq-aware', feedback='explicit',test_ratio=0.1, batch_size=256):\n",
        "    data, num_users, num_items = read_data_ml100k()\n",
        "    train_data, test_data = split_data_ml100k(data, num_users, num_items, split_mode, test_ratio)\n",
        "    _, _, _, train_inter_mat = load_data_ml100k(train_data, num_users, num_items, feedback)\n",
        "    _, _, _, test_inter_mat = load_data_ml100k(test_data, num_users, num_items, feedback)\n",
        "    \n",
        "    train_inter_mat = torch.tensor(train_inter_mat,dtype=torch.float32)\n",
        "    test_inter_mat = torch.tensor(test_inter_mat,dtype=torch.float32)\n",
        "\n",
        "    train_iter= create_iterator ((train_inter_mat),batch_size=batch_size,is_train=True)\n",
        "    \n",
        "    test_iter= create_iterator ((test_inter_mat),batch_size=batch_size*4,is_train=False)\n",
        "    return num_users,num_items,train_iter, test_iter"
      ],
      "metadata": {
        "id": "eMFgdNhXgXby"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_users, num_items, train_iter, test_iter= split_and_load_ml100k(split_mode='seq-aware', feedback='explicit',test_ratio=0.1, batch_size=256)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1om2r5ygZmp",
        "outputId": "e0dd8997-04c7-4696-f81e-3370f5ef0228"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100000/100000 [00:00<00:00, 959959.72it/s]\n",
            "100%|██████████| 99057/99057 [00:00<00:00, 720198.26it/s]\n",
            "100%|██████████| 943/943 [00:00<00:00, 645435.49it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(num_users, num_items)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-f42R2srF5s",
        "outputId": "9abb31c7-1e52-4720-8337-606c165f3d57"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "943 1682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_iter:\n",
        "  print(len(batch))\n",
        "  print(batch[0].shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuHPB5MJgZn_",
        "outputId": "ff00cab2-a6ff-4c69-8899-855d480b99b6"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "256\n",
            "torch.Size([943])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in test_iter:\n",
        "  print(len(batch))\n",
        "  print(batch[0].shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPW7om_KDBMV",
        "outputId": "601ab268-d50a-49b0-dbe4-efb79a02351e"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1024\n",
            "torch.Size([943])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_iter),len(test_iter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cWLhTxUthjS",
        "outputId": "3abaed1f-5f2f-4d88-d9a6-33dddc60932a"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Building the Model\n",
        "\n",
        "\n",
        "On one hand, AutoRec has the same structure as an autoencoder which consists of an input layer, a hidden layer, and a reconstruction (output) layer.  An autoencoder is a neural network that learns to copy its input to its output in order to code the inputs into the hidden (and usually low-dimensional) representations. **In AutoRec, instead of explicitly embedding users/items into low-dimensional space, it uses the column/row of the interaction matrix as the input, then reconstructs the interaction matrix in the output layer.**\n",
        "\n",
        "On the other hand, AutoRec differs from a traditional autoencoder: rather than learning the hidden representations, AutoRec focuses on learning/reconstructing the output layer. It uses a partially observed interaction matrix as the input, aiming to reconstruct a completed rating matrix. In the meantime, the missing entries of the input are filled in the output layer via reconstruction for the purpose of recommendation. \n",
        "\n",
        "**There are two variants of AutoRec: user-based and item-based. For brevity, here we only introduce the item-based AutoRec. User-based AutoRec can be derived accordingly.**\n",
        "\n",
        "**This means that in a batch for every item in that batch we have an input of len num_users which shows what that item is rated by every user. Of course the items not rated by the user are represented by zero and masked out as we will see.**\n",
        "\n",
        "\n",
        "Let $\\mathbf{R}_{*i}$ denote the $i^\\mathrm{th}$ column of the rating matrix, where unknown ratings are set to zeros by default. The neural architecture is defined as:\n",
        "\n",
        "$$\n",
        "h(\\mathbf{R}_{*i}) = f(\\mathbf{W} \\cdot g(\\mathbf{V} \\mathbf{R}_{*i} + \\mu) + b)\n",
        "$$\n",
        "\n",
        "where $f(\\cdot)$ and $g(\\cdot)$ represent activation functions, $\\mathbf{W}$ and $\\mathbf{V}$ are weight matrices, $\\mu$ and $b$ are biases. Let $h( \\cdot )$ denote the whole network of AutoRec. The output $h(\\mathbf{R}_{*i})$ is the reconstruction of the $i^\\mathrm{th}$ column of the rating matrix.\n",
        "\n",
        "The following objective function aims to minimize the reconstruction error:\n",
        "\n",
        "$$\n",
        "\\underset{\\mathbf{W},\\mathbf{V},\\mu, b}{\\mathrm{argmin}} \\sum_{i=1}^M{\\parallel \\mathbf{R}_{*i} - h(\\mathbf{R}_{*i})\\parallel_{\\mathcal{O}}^2} +\\lambda(\\| \\mathbf{W} \\|_F^2 + \\| \\mathbf{V}\\|_F^2)\n",
        "$$\n",
        "\n",
        "where $\\| \\cdot \\|_{\\mathcal{O}}$ means only the contribution of observed ratings are considered, that is, only weights that are associated with observed inputs are updated during back-propagation.\n"
      ],
      "metadata": {
        "id": "2SjIdRmIme8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AutoRec(nn.Module):\n",
        "  def __init__(self,num_hiddens,num_users,dropout=0.05):\n",
        "    super(AutoRec, self).__init__()\n",
        "    self.encoder = nn.Linear(num_users,num_hiddens,bias=True)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.decoder = nn.Linear(num_hiddens,num_users, bias=True)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "  \n",
        "  def forward(self,inputs):\n",
        "    #inputs -> batch_size X num_users\n",
        "    hidden = self.dropout(self.sigmoid(self.encoder(inputs)))\n",
        "    preds= self.decoder(hidden)\n",
        "    #if self.training:  # Mask the gradient during training\n",
        "    return preds\n",
        "    #else: \n",
        "      #return preds\n"
      ],
      "metadata": {
        "id": "yA9f1QcGmcqD"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(m):\n",
        "  if type(m) == nn.Linear:\n",
        "    nn.init.normal_(m.weight,0.01)\n"
      ],
      "metadata": {
        "id": "1cw5GSOfs_Y7"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_rmse_gpu(net, data_iter, device=None):\n",
        "  if isinstance(net, nn.Module):\n",
        "    net.eval() # Set the model to evaluation mode \n",
        "    if not device:\n",
        "      device = next(iter(net.parameters())).device \n",
        "\n",
        "  # No. of correct predictions, no. of predictions \n",
        "  scores=[]\n",
        "  with torch.no_grad():\n",
        "    for batch in data_iter:\n",
        "      batch = batch.to(device)\n",
        "      preds = net(batch) * (batch > 0).to(torch.float32)\n",
        "      se = nn.MSELoss(reduction='mean')(preds,batch)\n",
        "      scores.append(se)\n",
        "\n",
        "  return torch.sqrt(sum(scores)/len(scores)).item()"
      ],
      "metadata": {
        "id": "vPNGF83ytOlT"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_batch(net,X,y,loss,optimizer,devices=d2l.try_all_gpus()):\n",
        "  X = X.to(devices[0])\n",
        "  y = y.to(devices[0])\n",
        "  net.train()\n",
        "  optimizer.zero_grad()\n",
        "  pred = net(X) * (y > 0).to(torch.float32)\n",
        "  l = loss(pred,y)\n",
        "  l.backward()\n",
        "  optimizer.step()\n",
        "  \n",
        "  return l"
      ],
      "metadata": {
        "id": "uS-_Z55xtSLH"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn.MSELoss(reduction='none')(torch.tensor([[1,2],[0,0]],dtype=torch.float32),torch.tensor([[1,1],[0,5]],dtype=torch.float32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nX9mFDX-0Sh",
        "outputId": "32508317-6f50-408c-8c0e-8573294d6f6f"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.],\n",
              "        [ 0., 25.]])"
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn.MSELoss(reduction='sum')(torch.tensor([[1,2],[-0,0]],dtype=torch.float32),torch.tensor([[1,2],[0,5]],dtype=torch.float32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqsZ25_dIqaG",
        "outputId": "b60fa14f-eae2-4fdc-c42c-f33cd13bf8db"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(25.)"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn.MSELoss(reduction='mean')(torch.tensor([[1,2],[-0,0]],dtype=torch.float32),torch.tensor([[1,2],[0,5]],dtype=torch.float32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDWbq3ngIrcU",
        "outputId": "c6742623-b0f7-4140-eba5-ba5a77d112f2"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6.2500)"
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(net, train_iter, test_iter, loss, trainer, num_epochs,devices=d2l.try_all_gpus()):\n",
        "  timer, num_batches = d2l.Timer(), len(train_iter)\n",
        "  net = nn.DataParallel(net, device_ids=devices).to(devices[0])\n",
        "  scores = []\n",
        "  for epoch in range(num_epochs):\n",
        "    for batch in train_iter:\n",
        "      timer.start()\n",
        "      l=train_batch(net,batch,batch,loss,trainer,devices)\n",
        "      scores.append(l)\n",
        "      timer.stop()\n",
        "    train_mse = (sum(scores)/len(scores)).item()\n",
        "    test_rmse = evaluate_rmse_gpu(net, test_iter)\n",
        "    print(f'epoch {epoch+1}: train MSE {train_mse:.3f} test RMSE {test_rmse:.3f}') \n"
      ],
      "metadata": {
        "id": "fjIenP07tT1w"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "devices = d2l.try_all_gpus()\n",
        "num_users, num_items, train_iter, test_iter = split_and_load_ml100k(test_ratio=0.1, batch_size=256)\n",
        "net = AutoRec(500, num_users)\n",
        "net.apply(init_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LD_5tJ601z2",
        "outputId": "2cdd58a2-74fb-45c6-b8cb-2126f26adc35"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100000/100000 [00:00<00:00, 930095.75it/s]\n",
            "100%|██████████| 99057/99057 [00:00<00:00, 749666.95it/s]\n",
            "100%|██████████| 943/943 [00:00<00:00, 354062.19it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AutoRec(\n",
              "  (encoder): Linear(in_features=943, out_features=500, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              "  (decoder): Linear(in_features=500, out_features=943, bias=True)\n",
              "  (dropout): Dropout(p=0.05, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "summary(net)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLqVZbE91CSk",
        "outputId": "574dfdab-31b8-455f-b6ea-2935ca1a87e8"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "AutoRec                                  --\n",
              "├─Linear: 1-1                            472,000\n",
              "├─Sigmoid: 1-2                           --\n",
              "├─Linear: 1-3                            472,443\n",
              "├─Dropout: 1-4                           --\n",
              "=================================================================\n",
              "Total params: 944,443\n",
              "Trainable params: 944,443\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr, num_epochs, wd= 0.1, 50, 1e-5\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=wd)\n",
        "\n",
        "loss = nn.MSELoss(reduction='mean')\n",
        "\n",
        "train(net, train_iter, test_iter, loss, optimizer, num_epochs,devices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHywwcW61QVx",
        "outputId": "d37eaaec-c230-4488-907e-a733fd63cbeb"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: train MSE 9.164 test RMSE 0.384\n",
            "epoch 2: train MSE 5.470 test RMSE 0.327\n",
            "epoch 3: train MSE 3.932 test RMSE 0.284\n",
            "epoch 4: train MSE 3.079 test RMSE 0.260\n",
            "epoch 5: train MSE 2.537 test RMSE 0.232\n",
            "epoch 6: train MSE 2.160 test RMSE 0.212\n",
            "epoch 7: train MSE 1.884 test RMSE 0.199\n",
            "epoch 8: train MSE 1.673 test RMSE 0.186\n",
            "epoch 9: train MSE 1.507 test RMSE 0.175\n",
            "epoch 10: train MSE 1.372 test RMSE 0.164\n",
            "epoch 11: train MSE 1.261 test RMSE 0.156\n",
            "epoch 12: train MSE 1.168 test RMSE 0.147\n",
            "epoch 13: train MSE 1.089 test RMSE 0.140\n",
            "epoch 14: train MSE 1.020 test RMSE 0.133\n",
            "epoch 15: train MSE 0.960 test RMSE 0.128\n",
            "epoch 16: train MSE 0.907 test RMSE 0.122\n",
            "epoch 17: train MSE 0.860 test RMSE 0.116\n",
            "epoch 18: train MSE 0.819 test RMSE 0.111\n",
            "epoch 19: train MSE 0.781 test RMSE 0.107\n",
            "epoch 20: train MSE 0.747 test RMSE 0.103\n",
            "epoch 21: train MSE 0.716 test RMSE 0.100\n",
            "epoch 22: train MSE 0.688 test RMSE 0.096\n",
            "epoch 23: train MSE 0.662 test RMSE 0.093\n",
            "epoch 24: train MSE 0.638 test RMSE 0.090\n",
            "epoch 25: train MSE 0.616 test RMSE 0.087\n",
            "epoch 26: train MSE 0.595 test RMSE 0.085\n",
            "epoch 27: train MSE 0.576 test RMSE 0.082\n",
            "epoch 28: train MSE 0.558 test RMSE 0.080\n",
            "epoch 29: train MSE 0.542 test RMSE 0.077\n",
            "epoch 30: train MSE 0.526 test RMSE 0.075\n",
            "epoch 31: train MSE 0.511 test RMSE 0.073\n",
            "epoch 32: train MSE 0.498 test RMSE 0.072\n",
            "epoch 33: train MSE 0.485 test RMSE 0.069\n",
            "epoch 34: train MSE 0.472 test RMSE 0.068\n",
            "epoch 35: train MSE 0.461 test RMSE 0.066\n",
            "epoch 36: train MSE 0.449 test RMSE 0.065\n",
            "epoch 37: train MSE 0.439 test RMSE 0.063\n",
            "epoch 38: train MSE 0.429 test RMSE 0.062\n",
            "epoch 39: train MSE 0.420 test RMSE 0.060\n",
            "epoch 40: train MSE 0.411 test RMSE 0.059\n",
            "epoch 41: train MSE 0.402 test RMSE 0.057\n",
            "epoch 42: train MSE 0.394 test RMSE 0.056\n",
            "epoch 43: train MSE 0.386 test RMSE 0.056\n",
            "epoch 44: train MSE 0.378 test RMSE 0.054\n",
            "epoch 45: train MSE 0.371 test RMSE 0.052\n",
            "epoch 46: train MSE 0.364 test RMSE 0.054\n",
            "epoch 47: train MSE 0.358 test RMSE 0.051\n",
            "epoch 48: train MSE 0.352 test RMSE 0.049\n",
            "epoch 49: train MSE 0.345 test RMSE 0.049\n",
            "epoch 50: train MSE 0.339 test RMSE 0.047\n"
          ]
        }
      ]
    }
  ]
}